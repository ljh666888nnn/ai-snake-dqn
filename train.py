import argparse
import pygame
import numpy as np
from snake_game import SnakeGameAI
from agent import Agent
from visualize import VisualizeTraining
import torch
from collections import Counter

def train(model_type="dqn", max_games=5000, save_interval=100, show_game=False, speed=100, show_plots=False):
    """
    è®­ç»ƒè´ªåƒè›‡AI
    """
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒè´ªåƒè›‡AI")
    print(f"æ¨¡å‹: {model_type}")
    print(f"æ¸¸æˆæ•°é‡: {max_games}")
    print(f"ä¿å­˜é—´éš”: {save_interval}")
    print(f"æ˜¾ç¤ºæ¸¸æˆ: {'æ˜¯' if show_game else 'å¦'}")
    print(f"æ¸¸æˆé€Ÿåº¦: {speed}")
    print("-" * 50)
    
    # åˆå§‹åŒ–
    agent = Agent(model_type=model_type)
    game = SnakeGameAI(speed=speed)
    visualizer = VisualizeTraining(show_plots=show_plots)
    
    # è®­ç»ƒæ•°æ®è®°å½•
    scores = []
    mean_scores = []
    losses = []
    epsilons = []
    snake_lengths = []
    mean_lengths = []
    death_reasons = []
    
    total_score = 0
    record = 0
    
    print(f"å¼€å§‹è®­ç»ƒå¾ªç¯ï¼Œç›®æ ‡{max_games}å±€...")
    
    for game_num in range(max_games):
        # å†…éƒ¨æ¸¸æˆå¾ªç¯
        while True:
            # è®¾ç½®å½“å‰æ¸¸æˆå¼•ç”¨ï¼Œç”¨äºå®‰å…¨æ£€æŸ¥
            agent.set_current_game(game)
            
            # è·å–æ—§çŠ¶æ€
            state_old = agent.get_state(game)
            
            # è·å–åŠ¨ä½œ
            final_move = agent.get_action(state_old)
            
            # æ‰§è¡ŒåŠ¨ä½œå¹¶è·å–æ–°çŠ¶æ€
            reward, done, score = game.play_step(final_move)
            state_new = agent.get_state(game)
            
            # è®­ç»ƒçŸ­æœŸè®°å¿†
            agent.remember(state_old, final_move, reward, state_new, done)
            
            if done:
                # æ¸¸æˆç»“æŸå¤„ç†
                game.reset()
                agent.n_games += 1
                
                # è®­ç»ƒé•¿æœŸè®°å¿†
                current_loss = 0
                if len(agent.memory) > 1000:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç»éªŒ
                    current_loss = agent.train_long_memory()
                    if current_loss is None:
                        current_loss = 0
                
                losses.append(current_loss)
                
                # è®°å½•æ­»äº¡åŸå› 
                if hasattr(game, 'death_reason') and game.death_reason:
                    death_reasons.append(game.death_reason)
                
                # æ›´æ–°è®°å½•
                if score > record:
                    record = score
                    # ä¿å­˜æœ€ä½³æ¨¡å‹
                    if model_type == "linear":
                        agent.model.save('best_linear_model.pth')
                    else:
                        agent.model.save('best_dqn_model.pth')
                
                # è®°å½•ç»Ÿè®¡æ•°æ®
                total_score += score
                mean_score = total_score / agent.n_games
                current_length = 3 + score  # åˆå§‹é•¿åº¦3 + åˆ†æ•°
                
                scores.append(score)
                mean_scores.append(mean_score)
                epsilons.append(agent.epsilon)
                snake_lengths.append(current_length)
                
                if snake_lengths:
                    mean_length = sum(snake_lengths) / len(snake_lengths)
                    mean_lengths.append(mean_length)
                else:
                    mean_lengths.append(current_length)
                
                # æ›´æ–°å¯è§†åŒ–å™¨çš„æ•°æ®
                visualizer.scores = scores
                visualizer.mean_scores = mean_scores
                visualizer.losses = losses
                visualizer.epsilons = epsilons
                visualizer.snake_lengths = snake_lengths
                visualizer.mean_lengths = mean_lengths
                
                # å®šæœŸè¾“å‡ºè¿›åº¦ï¼ˆæ¯50å±€ï¼‰
                if agent.n_games % 50 == 0 or agent.n_games <= 10:
                    current_lr = agent.optimizer.param_groups[0]['lr']
                    print(f'æ¸¸æˆ {agent.n_games:4d}/{max_games}: åˆ†æ•°={score:2d}, è®°å½•={record:2d}, '
                          f'å¹³å‡åˆ†={mean_score:.2f}, è›‡é•¿={current_length:2d}, '
                          f'å¹³å‡é•¿åº¦={mean_length:.2f}, Îµ={agent.epsilon:.1f}, '
                          f'æŸå¤±={current_loss:.4f}, lr={current_lr:.6f}')
                
                # å®šæœŸä¿å­˜å’Œç»Ÿè®¡
                if agent.n_games % save_interval == 0:
                    print(f'\n=== ç¬¬ {agent.n_games} å±€æ£€æŸ¥ç‚¹ ===')
                    
                    # ä¿å­˜æ¨¡å‹
                    if model_type == "linear":
                        agent.model.save(f'checkpoint_linear_{agent.n_games}.pth')
                    else:
                        agent.model.save(f'checkpoint_dqn_{agent.n_games}.pth')
                    
                    # æ­»äº¡åŸå› ç»Ÿè®¡
                    if death_reasons:
                        death_stats = Counter(death_reasons)
                        total_deaths = len(death_reasons)
                        print("æ­»äº¡åŸå› ç»Ÿè®¡:")
                        for reason, count in death_stats.most_common():
                            percentage = (count / total_deaths) * 100
                            print(f"  {reason}: {count}æ¬¡ ({percentage:.1f}%)")
                    
                    # ä¿å­˜å¯è§†åŒ– - ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•å
                    visualizer.save_plot(game_number=agent.n_games, include_length=True)
                    
                    print(f'æ£€æŸ¥ç‚¹å·²ä¿å­˜ - å¹³å‡åˆ†: {mean_score:.2f}, æœ€é«˜åˆ†: {record}')
                    print('=' * 50)
                
                # é€€å‡ºå†…éƒ¨å¾ªç¯ï¼Œè¿›å…¥ä¸‹ä¸€å±€æ¸¸æˆ
                break
    
    # è®­ç»ƒå®Œæˆ
    print('\nğŸ‰ è®­ç»ƒå®Œæˆ!')
    print(f'æ€»æ¸¸æˆæ•°: {max_games}')
    print(f'æœ€é«˜åˆ†: {record}')
    print(f'æœ€ç»ˆå¹³å‡åˆ†: {mean_score:.2f}')
    if mean_lengths:
        print(f'æœ€ç»ˆå¹³å‡è›‡é•¿: {mean_lengths[-1]:.2f}')
    
    # æœ€ç»ˆç»Ÿè®¡
    if death_reasons:
        print("\nğŸ“Š æœ€ç»ˆæ­»äº¡åŸå› ç»Ÿè®¡:")
        death_stats = Counter(death_reasons)
        total_deaths = len(death_reasons)
        for reason, count in death_stats.most_common():
            percentage = (count / total_deaths) * 100
            print(f"  {reason}: {count}æ¬¡ ({percentage:.1f}%)")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹å’Œå¯è§†åŒ–
    final_model_name = f'final_{model_type}_model_{max_games}games.pth'
    agent.model.save(final_model_name)
    print(f"\nğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_model_name}")
    
    # æœ€ç»ˆå¯è§†åŒ– - ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•å
    visualizer.save_plot(filename='final_training_plot.png', include_length=True)
    
    pygame.quit()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='è®­ç»ƒè´ªåƒè›‡AI')
    parser.add_argument('--model', type=str, default='dqn', choices=['linear', 'dqn'], 
                        help='æ¨¡å‹ç±»å‹: linear æˆ– dqn (é»˜è®¤: dqn)')
    parser.add_argument('--games', type=int, default=5000, 
                        help='è®­ç»ƒæ¸¸æˆæ•°é‡ (é»˜è®¤: 5000)')
    parser.add_argument('--interval', type=int, default=100, 
                        help='ä¿å­˜é—´éš” (é»˜è®¤: 100)')
    parser.add_argument('--show', action='store_true', 
                        help='æ˜¾ç¤ºæ¸¸æˆç•Œé¢')
    parser.add_argument('--no-show', action='store_true', 
                        help='ä¸æ˜¾ç¤ºæ¸¸æˆç•Œé¢ (é»˜è®¤)')
    parser.add_argument('--speed', type=int, default=100, 
                        help='æ¸¸æˆé€Ÿåº¦ (é»˜è®¤: 100)')
    parser.add_argument('--plots', action='store_true',
                        help='æ˜¾ç¤ºå®æ—¶å›¾è¡¨')
    
    args = parser.parse_args()
    
    # ç¡®å®šæ˜¯å¦æ˜¾ç¤ºæ¸¸æˆ
    show_game = args.show and not args.no_show
    
    train(
        model_type=args.model,
        max_games=args.games,
        save_interval=args.interval,
        show_game=show_game,
        speed=args.speed,
        show_plots=args.plots
    ) 